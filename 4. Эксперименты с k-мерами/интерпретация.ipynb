{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Graph dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, Data\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# GNN Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv, GATConv, GATv2Conv, SAGEConv\n",
    "\n",
    "\n",
    "# Sparse vector\n",
    "from Sparse_vector.sparse_vector import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_names = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "\n",
    "features = [i[:-4] for i in os.listdir('z_dna/hg38_features/sparse/') if i.endswith('.pkl')]\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"z_dna/hg38_dna/{file}\") for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9f912bb28d4733a109309aca9d593b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ac2010dfb34333ac4db52b601fc458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 4.78 s, total: 2min 17s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chrom_names)}\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_shin.pkl')\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "DNA_features = {feature: load(f'z_dna/hg38_features/sparse/{feature}.pkl')\n",
    "                for feature in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# Функция для генерации подгрупп (subgroups)\n",
    "def generate_subgroups(n):\n",
    "    nucleotides = ['A', 'T', 'G', 'C']\n",
    "    subgroups = []\n",
    "    for i in range(1, n + 1):  # Генерация комбинаций длиной от 1 до n\n",
    "        subgroups.extend([''.join(p) for p in product(nucleotides, repeat=i)])\n",
    "    return subgroups\n",
    "\n",
    "# Функция для кодирования последовательности\n",
    "def encode_sequence_as_features_ndarray(n_str: str, k_str: str):\n",
    "    n = len(n_str)\n",
    "    k = len(k_str)\n",
    "    result = np.zeros(n, dtype=int)\n",
    "    \n",
    "    for i in range(n - k + 1):\n",
    "        if n_str[i:i+k] == k_str:\n",
    "            result[i:i+k] = 1\n",
    "    \n",
    "    return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, chroms, features,\n",
    "                 dna_source, features_source,\n",
    "                 labels, intervals,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels = labels\n",
    "        self.intervals = intervals\n",
    "        self.groups = generate_subgroups(4)\n",
    "        self.k_mer = 4\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "\n",
    "        self.ei = [[],[]]\n",
    "        for i in range(width-1):\n",
    "            self.ei[0].append(i)\n",
    "            self.ei[0].append(i+1)\n",
    "            self.ei[1].append(i+1)\n",
    "            self.ei[1].append(i)\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def get(self, idx):\n",
    "        interval = self.intervals[idx]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        \n",
    "        dna_OHE = []\n",
    "        \n",
    "        for group in self.groups:\n",
    "            #print(group)\n",
    "            featuress = encode_sequence_as_features_ndarray(self.dna_source[chrom][begin:end].upper(), group)\n",
    "            \n",
    "            dna_OHE.append(featuress)\n",
    "        \n",
    "        dna_OHE = list(map(list, zip(*dna_OHE)))\n",
    "        dna_OHE = np.array(dna_OHE)\n",
    "\n",
    "        feature_matr = []\n",
    "        #for feature in self.features:\n",
    "        #    source = self.features_source[feature]\n",
    "        #    feature_matr.append(source[chrom][begin:end])\n",
    "\n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "\n",
    "        edge_index = torch.tensor(np.array(self.ei), dtype=torch.long)\n",
    "\n",
    "        y = self.labels[interval[0]][interval[1]: interval[2]]\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "        return Data(x=X.unsqueeze(0), edge_index=edge_index, y=y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 2489564/2489564 [00:42<00:00, 59128.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 2421935/2421935 [00:38<00:00, 62800.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1982955/1982955 [00:30<00:00, 64041.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1902145/1902145 [00:30<00:00, 62759.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1815382/1815382 [00:29<00:00, 62437.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1708059/1708059 [00:27<00:00, 61474.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1593459/1593459 [00:24<00:00, 65748.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1451386/1451386 [00:24<00:00, 59584.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1383947/1383947 [00:20<00:00, 68531.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1337974/1337974 [00:20<00:00, 66017.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1350866/1350866 [00:22<00:00, 59796.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1332753/1332753 [00:20<00:00, 65765.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1143643/1143643 [00:17<00:00, 66012.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1070437/1070437 [00:16<00:00, 66038.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1019911/1019911 [00:15<00:00, 66254.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 903383/903383 [00:16<00:00, 53976.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 832574/832574 [00:12<00:00, 66166.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 803732/803732 [00:12<00:00, 62349.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 586176/586176 [00:08<00:00, 66076.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 644441/644441 [00:09<00:00, 65734.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 467099/467099 [00:07<00:00, 64554.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 508184/508184 [00:07<00:00, 64303.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1560408/1560408 [00:23<00:00, 65648.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 572274/572274 [00:12<00:00, 47112.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 51025.60it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "width = 100\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "for chrm in chrom_names:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "            ints_in.append([chrm, interval[0], interval[1]])\n",
    "        else:\n",
    "            ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 2, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "equalized = np.vstack((ints_in, ints_out))\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]\n",
    "\n",
    "train_inds, test_inds = next(StratifiedKFold().split(equalized, [f\"{int(i < 400)}_{elem[0]}\"\n",
    "                                                                 for i, elem\n",
    "                                                                 in enumerate(equalized)]))\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gc_cg(sequences):\n",
    "    # Создаём пустой список для результатов\n",
    "    filtered_sequences = []\n",
    "    \n",
    "    # Перебираем каждую последовательность в массиве\n",
    "    for seq in sequences:\n",
    "        # Проверяем, содержит ли последовательность \"GC\" или \"CG\"\n",
    "        if \"GC\" in seq or \"CG\" in seq:\n",
    "            # Если да, добавляем её в результат\n",
    "            filtered_sequences.append(seq)\n",
    "    \n",
    "    # Возвращаем отфильтрованный список\n",
    "    return filtered_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 4\n",
    "groups = generate_subgroups(max_length)\n",
    "features_count = len(groups)\n",
    "\n",
    "np.random.seed(42)\n",
    "features_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                            DNA, DNA_features,\n",
    "                            ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                           DNA, DNA_features,\n",
    "                           ZDNA, test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':32,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphZSAGEConv_13L(torch.nn.Module):\n",
    "    def __init__(self, top_count):\n",
    "        super(GraphZSAGEConv_13L, self).__init__()\n",
    "        \n",
    "        self.conv1 = SAGEConv(top_count, 1024)\n",
    "        self.conv2 = SAGEConv(1024, 1024)\n",
    "        self.conv3 = SAGEConv(1024, 512)\n",
    "        self.conv4 = SAGEConv(512, 512)\n",
    "        self.conv5 = SAGEConv(512, 256)\n",
    "        \n",
    "        self.conv6 = SAGEConv(256, 256)\n",
    "        self.conv7 = SAGEConv(256, 128)\n",
    "        self.conv8 = SAGEConv(128, 128)\n",
    "        self.conv9 = SAGEConv(128, 64)\n",
    "        self.conv10 = SAGEConv(64, 64)\n",
    "        \n",
    "        self.conv11 = SAGEConv(64, 32)\n",
    "        self.conv12 = SAGEConv(32, 32)\n",
    "        self.conv13 = SAGEConv(32, 2)\n",
    "        \n",
    "        self.norm1 = torch.nn.GroupNorm(num_groups=512, num_channels=1024)\n",
    "        self.norm2 = torch.nn.GroupNorm(num_groups=512, num_channels=1024)\n",
    "        self.norm3 = torch.nn.GroupNorm(num_groups=256, num_channels=512)\n",
    "        self.norm4 = torch.nn.GroupNorm(num_groups=256, num_channels=512)\n",
    "        self.norm5 = torch.nn.GroupNorm(num_groups=128, num_channels=256)\n",
    "        self.norm6 = torch.nn.GroupNorm(num_groups=128, num_channels=256)\n",
    "        self.norm7 = torch.nn.GroupNorm(num_groups=64, num_channels=128)\n",
    "        self.norm8 = torch.nn.GroupNorm(num_groups=64, num_channels=128)\n",
    "        self.norm9 = torch.nn.GroupNorm(num_groups=32, num_channels=64)\n",
    "        self.norm10 = torch.nn.GroupNorm(num_groups=32, num_channels=64)\n",
    "        self.norm11 = torch.nn.GroupNorm(num_groups=16, num_channels=32)\n",
    "        self.norm12 = torch.nn.GroupNorm(num_groups=16, num_channels=32)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm1(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm2(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        \n",
    "        x = self.conv3(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm3(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv4(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm4(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv5(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm5(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv6(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm6(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv7(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm7(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv8(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm8(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv9(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm9(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv10(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm10(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv11(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm11(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv12(x, edge.to('cuda:1'))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm12(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        \n",
    "        x = self.conv13(x, edge.cuda())\n",
    "\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphZSAGEConv_v5_lin(\n",
       "  (conv1): SAGEConv(390, 1800, aggr=mean)\n",
       "  (conv2): SAGEConv(1800, 1650, aggr=mean)\n",
       "  (conv3): SAGEConv(1650, 1500, aggr=mean)\n",
       "  (conv4): SAGEConv(1500, 1350, aggr=mean)\n",
       "  (conv5): SAGEConv(1350, 1200, aggr=mean)\n",
       "  (conv6): SAGEConv(1200, 1050, aggr=mean)\n",
       "  (conv7): SAGEConv(1050, 900, aggr=mean)\n",
       "  (conv8): SAGEConv(900, 750, aggr=mean)\n",
       "  (conv9): SAGEConv(750, 600, aggr=mean)\n",
       "  (conv10): SAGEConv(600, 450, aggr=mean)\n",
       "  (conv11): SAGEConv(450, 300, aggr=mean)\n",
       "  (conv12): SAGEConv(300, 150, aggr=mean)\n",
       "  (conv13): SAGEConv(150, 64, aggr=mean)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphZSAGEConv_13L()\n",
    "model= torch.load(\"model_GC_5.pt\")\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphZSAGEConv_v5_lin(\n",
       "  (conv1): SAGEConv(340, 1800, aggr=mean)\n",
       "  (conv2): SAGEConv(1800, 1650, aggr=mean)\n",
       "  (conv3): SAGEConv(1650, 1500, aggr=mean)\n",
       "  (conv4): SAGEConv(1500, 1350, aggr=mean)\n",
       "  (conv5): SAGEConv(1350, 1200, aggr=mean)\n",
       "  (conv6): SAGEConv(1200, 1050, aggr=mean)\n",
       "  (conv7): SAGEConv(1050, 900, aggr=mean)\n",
       "  (conv8): SAGEConv(900, 750, aggr=mean)\n",
       "  (conv9): SAGEConv(750, 600, aggr=mean)\n",
       "  (conv10): SAGEConv(600, 450, aggr=mean)\n",
       "  (conv11): SAGEConv(450, 300, aggr=mean)\n",
       "  (conv12): SAGEConv(300, 150, aggr=mean)\n",
       "  (conv13): SAGEConv(150, 64, aggr=mean)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphZSAGEConv_13L()\n",
    "model= torch.load(\"model1234_86_2.pt\")\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum methods: IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in ./local/python3.9.0/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (2.3.0+cu121)\n",
      "Requirement already satisfied: tqdm in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (4.66.4)\n",
      "Requirement already satisfied: filelock in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (1.13.0)\n",
      "Requirement already satisfied: networkx in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./local/python3.9.0/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->captum) (12.5.82)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./local/python3.9.0/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->captum) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in ./local/python3.9.0/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./local/python3.9.0/lib/python3.9/site-packages (from jinja2->torch>=1.6->captum) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./local/python3.9.0/lib/python3.9/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cc439ccc4e457cbddccae3830ac747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 2h 53min 13s, sys: 35.3 s, total: 2h 53min 49s\n",
      "Wall time: 2h 54min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "for dt in tqdm(loader_test):\n",
    "    x, edge, y = dt.x.cuda(), dt.edge_index.cuda(), dt.y.cuda().long()\n",
    "    valid_edges = (edge < width).all(dim=0)\n",
    "    edge = edge[:, valid_edges]\n",
    "\n",
    "    output = model(x, edge.squeeze())\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    explanation = explainer(x.squeeze(), edge)\n",
    "    #explanation.visualize_feature_importance(top_k=10)\n",
    "    \n",
    "    node_mask = explanation.node_mask\n",
    "\n",
    "    if node_mask[idxs, :].shape != (0, features_count):\n",
    "        node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "        node_mask = np.array(node_mask.cpu())\n",
    "        mean_1 += node_mask\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'mean_GraphZSAGEConv_13L_1234_IG.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# salency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('Saliency'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a45aadeacef41d8ab5cd0f17a30c1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alapteva/local/python3.9.0/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 8min 31s, sys: 30.9 s, total: 9min 2s\n",
      "Wall time: 9min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "for dt in tqdm(loader_test):\n",
    "    x, edge, y = dt.x.cuda(), dt.edge_index.cuda(), dt.y.cuda().long()\n",
    "    valid_edges = (edge < width).all(dim=0)\n",
    "    edge = edge[:, valid_edges]\n",
    "\n",
    "    output = model(x, edge.squeeze())\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    explanation = explainer(x.squeeze(), edge)\n",
    "    #explanation.visualize_feature_importance(top_k=10)\n",
    "    \n",
    "    node_mask = explanation.node_mask\n",
    "\n",
    "    if node_mask[idxs, :].shape != (0, features_count):\n",
    "        node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "        node_mask = np.array(node_mask.cpu())\n",
    "        mean_1 += node_mask\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'mean_GraphZSAGEConv_13L_Saliency_TP.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IxG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('InputXGradient'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23013ae9c0a47a89d9a0c697b87d9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 8min 30s, sys: 26.9 s, total: 8min 57s\n",
      "Wall time: 9min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "for dt in tqdm(loader_test):\n",
    "    x, edge, y = dt.x.cuda(), dt.edge_index.cuda(), dt.y.cuda().long()\n",
    "    valid_edges = (edge < width).all(dim=0)\n",
    "    edge = edge[:, valid_edges]\n",
    "\n",
    "    output = model(x, edge.squeeze())\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    explanation = explainer(x.squeeze(), edge)\n",
    "    #explanation.visualize_feature_importance(top_k=10)\n",
    "    \n",
    "    node_mask = explanation.node_mask\n",
    "\n",
    "    if node_mask[idxs, :].shape != (0, features_count):\n",
    "        node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "        node_mask = node_mask.cpu().detach().numpy()\n",
    "        mean_1 += node_mask\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'mean_GraphZSAGEConv_13L_IxG_TP.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('Deconvolution'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95f4159f1044c2ba367ff5d574077e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alapteva/local/python3.9.0/lib/python3.9/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:64: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 8min 29s, sys: 26.3 s, total: 8min 56s\n",
      "Wall time: 9min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "\n",
    "for dt in tqdm(loader_test):\n",
    "    x, edge, y = dt.x.cuda(), dt.edge_index.cuda(), dt.y.cuda().long()\n",
    "    valid_edges = (edge < width).all(dim=0)\n",
    "    edge = edge[:, valid_edges]\n",
    "\n",
    "    output = model(x, edge.squeeze())\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    explanation = explainer(x.squeeze(), edge)\n",
    "    #explanation.visualize_feature_importance(top_k=10)\n",
    "    \n",
    "    node_mask = explanation.node_mask\n",
    "\n",
    "    if node_mask[idxs, :].shape != (0, features_count):\n",
    "        node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "        node_mask = node_mask.cpu().detach().numpy()\n",
    "        mean_1 += node_mask\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'mean_GraphZSAGEConv_13L_GC_Deconvolution_TP.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('GuidedBackprop'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908241a0020e44d5ace3e9532889dec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 8min 38s, sys: 30.3 s, total: 9min 8s\n",
      "Wall time: 9min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "\n",
    "for dt in tqdm(loader_test):\n",
    "    x, edge, y = dt.x.cuda(), dt.edge_index.cuda(), dt.y.cuda().long()\n",
    "    valid_edges = (edge < width).all(dim=0)\n",
    "    edge = edge[:, valid_edges]\n",
    "\n",
    "    output = model(x, edge.squeeze())\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    explanation = explainer(x.squeeze(), edge)\n",
    "    #explanation.visualize_feature_importance(top_k=10)\n",
    "    \n",
    "    node_mask = explanation.node_mask\n",
    "\n",
    "    if node_mask[idxs, :].shape != (0, features_count):\n",
    "        node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "        node_mask = node_mask.cpu().detach().numpy()\n",
    "        mean_1 += node_mask\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'mean_GraphZSAGEConv_13L_GC_GuidedBackprop_TP.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=50),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28b988eb549ab9b315f59326ef658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 3h 18min 47s, sys: 1min 32s, total: 3h 20min 19s\n",
      "Wall time: 3h 20min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "\n",
    "for dt in tqdm(loader_test):\n",
    "    x, edge, y = dt.x.cuda(), dt.edge_index.cuda(), dt.y.cuda().long()\n",
    "    valid_edges = (edge < width).all(dim=0)\n",
    "    edge = edge[:, valid_edges]\n",
    "\n",
    "    output = model(x, edge.squeeze())\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    explanation = explainer(x.squeeze(), edge)\n",
    "    #explanation.visualize_feature_importance(top_k=10)\n",
    "    \n",
    "    node_mask = explanation.node_mask\n",
    "\n",
    "    if node_mask[idxs, :].shape != (0, features_count):\n",
    "        node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "        node_mask = np.array(node_mask.cpu())\n",
    "        mean_1 += node_mask\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'mean_GraphZSAGEConv_13L_GC_GNN_explainer_TP.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-меры с GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datа_IG = torch.load(\"mean_GraphZSAGEConv_v5_lin_5_GC_IG.pt\")\n",
    "datа_Salency = torch.load(\"mean_GraphZSAGEConv_13L_GC_Saliency_TP.pt\")\n",
    "datа_IxG = torch.load(\"mean_GraphZSAGEConv_13L_GC_IxG_TP.pt\")\n",
    "datа_Deconvolution = torch.load(\"mean_GraphZSAGEConv_13L_GC_Deconvolution_TP.pt\")\n",
    "datа_GuidedBackprop = torch.load(\"mean_GraphZSAGEConv_13L_GC_GuidedBackprop_TP.pt\")\n",
    "datа_GNN_explainer = torch.load(\"mean_GraphZSAGEConv_13L_GC_GNN_explainer_TP.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Feature': groups,\n",
    "                   #'Impact_IG': datа_IG,\n",
    "                   'Impact_Saliency' : datа_Salency,\n",
    "                   'Impact_IxG' : datа_IxG,\n",
    "                   'Impact_Deconvolution' : datа_Deconvolution,\n",
    "                   'Impact_GuidedBackprop' : datа_GuidedBackprop,\n",
    "                  'Impact_GNN_explainer' : datа_GNN_explainer\n",
    "                  })\n",
    "\n",
    "#df['Impact_IG'] = np.abs(df['Impact_IG'])\n",
    "df['Impact_Saliency'] = np.abs(df['Impact_Saliency'])\n",
    "df['Impact_IxG'] = np.abs(df['Impact_IxG'])\n",
    "df['Impact_Deconvolution'] = np.abs(df['Impact_Deconvolution'])\n",
    "df['Impact_GuidedBackprop'] = np.abs(df['Impact_GuidedBackprop'])\n",
    "df['Impact_GNN_explainer'] = np.abs(df['Impact_GNN_explainer'])\n",
    "\n",
    "p_deviation = pd.DataFrame() # сюда будем собирать процентные средние\n",
    "\n",
    "for column in df.columns:\n",
    "    if column == 'Feature':\n",
    "        continue\n",
    "    \n",
    "    mean = df[column].mean()\n",
    "    p_deviation[f'{column}_p_deviation'] = np.abs((((df[column] - mean) / mean) * 100)) # считаем процентное среднее\n",
    "    \n",
    "p_deviation['mean_deviation'] = p_deviation.mean(axis=1)\n",
    "p_deviation['Feature'] = df['Feature']\n",
    "features_range = p_deviation[['Feature','mean_deviation']].sort_values(by='mean_deviation', ascending=False)\n",
    "\n",
    "features_range.to_csv('result_5_GC_TP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-меры с GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datа_IG = torch.load(\"mean_GraphZSAGEConv_v5_lin_5_GC_IG.pt\")\n",
    "datа_Salency = torch.load(\"mean_GraphZSAGEConv_v5_lin_5_GC_Saliency.pt\")\n",
    "datа_IxG = torch.load(\"mean_GraphZSAGEConv_v5_lin_5_GC_IxG.pt\")\n",
    "datа_Deconvolution = torch.load(\"mean_GraphZSAGEConv_v5_lin_5_GC_Deconvolution.pt\")\n",
    "datа_GuidedBackprop = torch.load(\"mean_GraphZSAGEConv_v5_lin_5_GC_GuidedBackprop.pt\")\n",
    "datа_GNN_explainer = torch.load(\"mean_GraphZSAGEConv_v5_lin_5_GC_GNN_explainer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Feature': groups,\n",
    "                   #'Impact_IG': datа_IG,\n",
    "                   'Impact_Saliency' : datа_Salency,\n",
    "                   'Impact_IxG' : datа_IxG,\n",
    "                   'Impact_Deconvolution' : datа_Deconvolution,\n",
    "                   'Impact_GuidedBackprop' : datа_GuidedBackprop,\n",
    "                  #'Impact_GNN_explainer' : datа_GNN_explainer\n",
    "                  })\n",
    "\n",
    "#df['Impact_IG'] = np.abs(df['Impact_IG'])\n",
    "df['Impact_Saliency'] = np.abs(df['Impact_Saliency'])\n",
    "df['Impact_IxG'] = np.abs(df['Impact_IxG'])\n",
    "df['Impact_Deconvolution'] = np.abs(df['Impact_Deconvolution'])\n",
    "df['Impact_GuidedBackprop'] = np.abs(df['Impact_GuidedBackprop'])\n",
    "#df['Impact_GNN_explainer'] = np.abs(df['Impact_GNN_explainer'])\n",
    "\n",
    "p_deviation = pd.DataFrame() # сюда будем собирать процентные средние\n",
    "\n",
    "for column in df.columns:\n",
    "    if column == 'Feature':\n",
    "        continue\n",
    "    \n",
    "    mean = df[column].mean()\n",
    "    p_deviation[f'{column}_p_deviation'] = (((df[column] - mean) / mean) * 100) # считаем процентное среднее\n",
    "    \n",
    "p_deviation['mean_deviation'] = p_deviation.mean(axis=1)\n",
    "p_deviation['Feature'] = df['Feature']\n",
    "features_range = p_deviation[['Feature','mean_deviation']].sort_values(by='mean_deviation', ascending=False)\n",
    "\n",
    "features_range.to_csv('result_6_GC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>mean_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>CGCGC</td>\n",
       "      <td>535.473142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>GCGCG</td>\n",
       "      <td>521.918843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>GCACA</td>\n",
       "      <td>444.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>CGCGG</td>\n",
       "      <td>428.336893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>CGTGT</td>\n",
       "      <td>400.402222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ATCGA</td>\n",
       "      <td>-92.988782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>TACGC</td>\n",
       "      <td>-94.519388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>CTTGC</td>\n",
       "      <td>-95.395234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>TCGGT</td>\n",
       "      <td>-96.247785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>GTTCG</td>\n",
       "      <td>-98.026854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  mean_deviation\n",
       "360   CGCGC      535.473142\n",
       "255   GCGCG      521.918843\n",
       "221   GCACA      444.203700\n",
       "359   CGCGG      428.336893\n",
       "326   CGTGT      400.402222\n",
       "..      ...             ...\n",
       "23    ATCGA      -92.988782\n",
       "90    TACGC      -94.519388\n",
       "289   CTTGC      -95.395234\n",
       "144   TCGGT      -96.247785\n",
       "173   GTTCG      -98.026854\n",
       "\n",
       "[390 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyhton 3.9.0 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
