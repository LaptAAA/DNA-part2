{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Graph dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, Data\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# GNN Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv, GATConv, GATv2Conv, SAGEConv\n",
    "\n",
    "\n",
    "# Sparse vector\n",
    "from Sparse_vector.sparse_vector import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "import time\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_names = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "\n",
    "features = [i[:-4] for i in os.listdir('z_dna/hg38_features/sparse/') if i.endswith('_2.pkl')]\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"z_dna/hg38_dna/{file}\") for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  6.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1946/1946 [00:52<00:00, 36.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.3 s, sys: 4.84 s, total: 57.1 s\n",
      "Wall time: 56.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chrom_names)}\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_shin.pkl')\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "DNA_features = {feature: load(f'z_dna/hg38_features/sparse/{feature}.pkl')\n",
    "                for feature in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "def generate_fix_n_subgroups(n):\n",
    "    nucleotides = ['A', 'T', 'G', 'C']\n",
    "    subgroups = []\n",
    "    subgroups.extend([''.join(p) for p in product(nucleotides, repeat=n)])\n",
    "    return subgroups\n",
    "\n",
    "def generate_subgroups(n):\n",
    "    nucleotides = ['A', 'T', 'G', 'C']\n",
    "    subgroups = []\n",
    "    for i in range(1, n + 1):\n",
    "        subgroups.extend([''.join(p) for p in product(nucleotides, repeat=i)])\n",
    "    return subgroups\n",
    "\n",
    "def encode_sequence_as_features_ndarray(n_str: str, k_str: str):\n",
    "    n = len(n_str)\n",
    "    k = len(k_str)\n",
    "    result = np.zeros(n, dtype=int)\n",
    "    \n",
    "    for i in range(n - k + 1):\n",
    "        if n_str[i:i+k] == k_str:\n",
    "            result[i:i+k] = 1\n",
    "    \n",
    "    return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, chroms, features,\n",
    "                 dna_source, features_source,\n",
    "                 labels, intervals, k_mer=1, groups=['A','T','G','C'],\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels = labels\n",
    "        self.intervals = intervals\n",
    "        \n",
    "        self.k_mer = k_mer\n",
    "        self.groups = groups\n",
    "\n",
    "        self.ei = [[],[]]\n",
    "        for i in range(width-1):\n",
    "            self.ei[0].append(i)\n",
    "            self.ei[0].append(i+1)\n",
    "            self.ei[1].append(i+1)\n",
    "            self.ei[1].append(i)\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def get(self, idx):\n",
    "        interval = self.intervals[idx]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        \n",
    "        dna_OHE = []\n",
    "        \n",
    "        for group in self.groups:\n",
    "            featuress = encode_sequence_as_features_ndarray(self.dna_source[chrom][begin:end].upper(), group)\n",
    "            \n",
    "            dna_OHE.append(featuress)\n",
    "        \n",
    "        dna_OHE = list(map(list, zip(*dna_OHE)))\n",
    "        dna_OHE = np.array(dna_OHE)\n",
    "        feature_matr = []\n",
    "\n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "\n",
    "        edge_index = torch.tensor(np.array(self.ei), dtype=torch.long)\n",
    "\n",
    "        y = self.labels[interval[0]][interval[1]: interval[2]]\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "        return Data(x=X.unsqueeze(0), edge_index=edge_index, y=y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 2489564/2489564 [00:34<00:00, 71973.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 2421935/2421935 [00:32<00:00, 73930.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1982955/1982955 [00:26<00:00, 74496.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1902145/1902145 [00:25<00:00, 73785.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1815382/1815382 [00:24<00:00, 72735.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1708059/1708059 [00:22<00:00, 76424.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1593459/1593459 [00:22<00:00, 71818.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1451386/1451386 [00:19<00:00, 76112.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1383947/1383947 [00:19<00:00, 70684.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1337974/1337974 [00:17<00:00, 76674.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1350866/1350866 [00:17<00:00, 76063.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1332753/1332753 [00:19<00:00, 68077.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1143643/1143643 [00:14<00:00, 76867.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1070437/1070437 [00:13<00:00, 76680.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1019911/1019911 [00:13<00:00, 76090.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 903383/903383 [00:11<00:00, 76194.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 832574/832574 [00:10<00:00, 76716.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 803732/803732 [00:12<00:00, 62068.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 586176/586176 [00:07<00:00, 75635.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 644441/644441 [00:08<00:00, 76475.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 467099/467099 [00:06<00:00, 76553.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 508184/508184 [00:06<00:00, 75248.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1560408/1560408 [00:20<00:00, 76588.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 572274/572274 [00:07<00:00, 77015.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 58044.13it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "width = 100\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "for chrm in chrom_names:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "            ints_in.append([chrm, interval[0], interval[1]])\n",
    "        else:\n",
    "            ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 2, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_chr1' '1_chr1' '1_chr1' ... '0_chr18' '0_chr8' '0_chr6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "np.random.seed(42)\n",
    "equalized = np.vstack((ints_in, ints_out))\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]\n",
    "\n",
    "labels = np.array([1]*len(ints_in) + [0]*len(ints_out))\n",
    "chromes = [inter[0] for inter in equalized]\n",
    "strat_labels = np.array([f\"{label}_{chrom}\" for label, chrom in zip(labels, chromes)])\n",
    "print(strat_labels)\n",
    "  \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_inds, test_inds = next(sss.split(equalized, strat_labels))\n",
    "  \n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "max_k_mer_size = 5\n",
    "groups = generate_subgroups(max_k_mer_size)\n",
    "feature_count = len(groups)\n",
    "\n",
    "train_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                            DNA, DNA_features,\n",
    "                            ZDNA, train_intervals, max_k_mer_size, groups)\n",
    "\n",
    "test_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                           DNA, DNA_features,\n",
    "                           ZDNA, test_intervals, max_k_mer_size, groups)\n",
    "\n",
    "np.random.seed(42)\n",
    "params = {'batch_size':32,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score, average_precision_score, recall_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class GraphZSAGEConv_13L(torch.nn.Module):\n",
    "    def __init__(self, feature_count):\n",
    "        super(GraphZSAGEConv_13L, self).__init__()\n",
    "        \n",
    "        self.conv1 = SAGEConv(feature_count, 1024)\n",
    "        self.conv2 = SAGEConv(1024, 1024)\n",
    "        self.conv3 = SAGEConv(1024, 512)\n",
    "        self.conv4 = SAGEConv(512, 512)\n",
    "        self.conv5 = SAGEConv(512, 256)\n",
    "        \n",
    "        self.conv6 = SAGEConv(256, 256)\n",
    "        self.conv7 = SAGEConv(256, 128)\n",
    "        self.conv8 = SAGEConv(128, 128)\n",
    "        self.conv9 = SAGEConv(128, 64)\n",
    "        self.conv10 = SAGEConv(64, 64)\n",
    "        \n",
    "        self.conv11 = SAGEConv(64, 32)\n",
    "        self.conv12 = SAGEConv(32, 32)\n",
    "        self.conv13 = SAGEConv(32, 2)\n",
    "        \n",
    "        self.norm1 = torch.nn.GroupNorm(num_groups=512, num_channels=1024)\n",
    "        self.norm2 = torch.nn.GroupNorm(num_groups=512, num_channels=1024)\n",
    "        self.norm3 = torch.nn.GroupNorm(num_groups=256, num_channels=512)\n",
    "        self.norm4 = torch.nn.GroupNorm(num_groups=256, num_channels=512)\n",
    "        self.norm5 = torch.nn.GroupNorm(num_groups=128, num_channels=256)\n",
    "        self.norm6 = torch.nn.GroupNorm(num_groups=128, num_channels=256)\n",
    "        self.norm7 = torch.nn.GroupNorm(num_groups=64, num_channels=128)\n",
    "        self.norm8 = torch.nn.GroupNorm(num_groups=64, num_channels=128)\n",
    "        self.norm9 = torch.nn.GroupNorm(num_groups=32, num_channels=64)\n",
    "        self.norm10 = torch.nn.GroupNorm(num_groups=32, num_channels=64)\n",
    "        self.norm11 = torch.nn.GroupNorm(num_groups=16, num_channels=32)\n",
    "        self.norm12 = torch.nn.GroupNorm(num_groups=16, num_channels=32)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge):\n",
    "        \n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        x = self.conv1(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm1(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm2(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        \n",
    "        x = self.conv3(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm3(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv4(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm4(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv5(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm5(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv6(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm6(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv7(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm7(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv8(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm8(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv9(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm9(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv10(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm10(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv11(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm11(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv12(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm12(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        \n",
    "        x = self.conv13(x, edge)\n",
    "\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphZSAGEConv_13L(\n",
       "  (conv1): SAGEConv(1364, 1024, aggr=mean)\n",
       "  (conv2): SAGEConv(1024, 1024, aggr=mean)\n",
       "  (conv3): SAGEConv(1024, 512, aggr=mean)\n",
       "  (conv4): SAGEConv(512, 512, aggr=mean)\n",
       "  (conv5): SAGEConv(512, 256, aggr=mean)\n",
       "  (conv6): SAGEConv(256, 256, aggr=mean)\n",
       "  (conv7): SAGEConv(256, 128, aggr=mean)\n",
       "  (conv8): SAGEConv(128, 128, aggr=mean)\n",
       "  (conv9): SAGEConv(128, 64, aggr=mean)\n",
       "  (conv10): SAGEConv(64, 64, aggr=mean)\n",
       "  (conv11): SAGEConv(64, 32, aggr=mean)\n",
       "  (conv12): SAGEConv(32, 32, aggr=mean)\n",
       "  (conv13): SAGEConv(32, 2, aggr=mean)\n",
       "  (norm1): GroupNorm(512, 1024, eps=1e-05, affine=True)\n",
       "  (norm2): GroupNorm(512, 1024, eps=1e-05, affine=True)\n",
       "  (norm3): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
       "  (norm4): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
       "  (norm5): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
       "  (norm6): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
       "  (norm7): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
       "  (norm8): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
       "  (norm9): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "  (norm10): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "  (norm11): GroupNorm(16, 32, eps=1e-05, affine=True)\n",
       "  (norm12): GroupNorm(16, 32, eps=1e-05, affine=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphZSAGEConv_13L(feature_count)\n",
    "model.load_state_dict(torch.load(\"GraphZSAGEConv_11L_1_5_k_mers.pt\"))\n",
    "#model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum methods: IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in ./local/python3.9.0/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (2.3.0+cu121)\n",
      "Requirement already satisfied: tqdm in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (4.66.4)\n",
      "Requirement already satisfied: filelock in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (1.13.0)\n",
      "Requirement already satisfied: networkx in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./local/python3.9.0/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->captum) (12.5.82)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./local/python3.9.0/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->captum) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in ./local/python3.9.0/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./local/python3.9.0/lib/python3.9/site-packages (from jinja2->torch>=1.6->captum) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./local/python3.9.0/lib/python3.9/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_count = len(groups)\n",
    "features_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 27121/27121 [10:46:28<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 10h 43min 49s, sys: 1min 45s, total: 10h 45min 34s\n",
      "Wall time: 10h 46min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "        \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge, target=1)\n",
    "        node_mask = explanation.node_mask\n",
    "\n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1364,)\n",
      "[ 1.32936813e-03  7.77668408e-04  2.92216314e-03 ...  1.21453108e-04\n",
      " -1.73796021e-03  3.75329942e-05]\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.32936813e-03,  7.77668408e-04,  2.92216314e-03, ...,\n",
       "        1.21453108e-04, -1.73796021e-03,  3.75329942e-05])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_13L_1_5_k_mers_IG.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# salency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.base_model(x, edge_index) \n",
    "        a = out[:, :, 1] \n",
    "        return a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrappedmodel = WrappedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=CaptumExplainer('Saliency'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_count = len(groups)\n",
    "features_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/27121 [00:00<?, ?it/s]/home/alapteva/local/python3.9.0/lib/python3.9/site-packages/torch_geometric/explain/explainer.py:193: UserWarning: The 'target' should not be provided for the explanation type 'model'\n",
      "  warnings.warn(\n",
      "/home/alapteva/local/python3.9.0/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 27121/27121 [28:05<00:00, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 26min 48s, sys: 49.6 s, total: 27min 37s\n",
      "Wall time: 28min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "        \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge, target=1)\n",
    "        node_mask = explanation.node_mask\n",
    "\n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1364,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00147995, 0.00129851, 0.00237362, ..., 0.00142435, 0.00493159,\n",
       "       0.00426171])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_13L_1_5_k_mers_Saliency.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7642e-02, 1.9714e-02, 2.2653e-02,  ..., 2.6891e-09, 5.5811e-05,\n",
       "        1.6170e-03], dtype=torch.float64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('GraphZSAGEConv_13L_1_5_k_mers_Saliency.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IxG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=CaptumExplainer('InputXGradient'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 27121/27121 [40:28<00:00, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 35min 32s, sys: 4min 31s, total: 40min 3s\n",
      "Wall time: 40min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "   \n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "     \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "      \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "      \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge)\n",
    "        node_mask = explanation.node_mask\n",
    "        \n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.detach().cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1364,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.44478283e-05, -4.28186405e-05, -2.65626381e-04, ...,\n",
       "       -3.17674658e-06, -9.58518565e-05, -2.63277797e-05])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_13L_1_5_k_mers_IxG.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=GNNExplainer(epochs=50),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 27121/27121 [12:04:24<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 11h 45min 40s, sys: 18min 31s, total: 12h 4min 12s\n",
      "Wall time: 12h 4min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mean_1 = np.zeros(features_count, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "   \n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "     \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "      \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "      \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge)\n",
    "        node_mask = explanation.node_mask\n",
    "        \n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.detach().cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1364,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05584951, 0.05864221, 0.18252613, ..., 0.00302195, 0.01032195,\n",
       "       0.00502422])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_13L_1_5_k_mers_GNN_explainer.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyhton 3.9.0 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
