{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Graph dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, Data\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# GNN Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv, GATConv, GATv2Conv, SAGEConv\n",
    "\n",
    "\n",
    "# Sparse vector\n",
    "from Sparse_vector.sparse_vector import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "import time\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_names = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "\n",
    "features = [i[:-4] for i in os.listdir('z_dna/hg38_features/sparse/') if i.endswith('_2.pkl')]\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"z_dna/hg38_dna/{file}\") for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  6.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1946/1946 [00:57<00:00, 33.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.5 s, sys: 4.95 s, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chrom_names)}\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_shin.pkl')\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "DNA_features = {feature: load(f'z_dna/hg38_features/sparse/{feature}.pkl')\n",
    "                for feature in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, chroms, features,\n",
    "                 dna_source, features_source,\n",
    "                 labels, intervals,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels = labels\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "\n",
    "        self.ei = [[],[]]\n",
    "        for i in range(width-1):\n",
    "            self.ei[0].append(i)\n",
    "            self.ei[0].append(i+1)\n",
    "            self.ei[1].append(i+1)\n",
    "            self.ei[1].append(i)\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def get(self, idx):\n",
    "        interval = self.intervals[idx]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        dna_OHE = self.le.transform(list(self.dna_source[chrom][begin:end].upper()))\n",
    "\n",
    "        feature_matr = []\n",
    "        for feature in self.features:\n",
    "            source = self.features_source[feature]\n",
    "            feature_matr.append(source[chrom][begin:end])\n",
    "\n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "\n",
    "        edge_index = torch.tensor(np.array(self.ei), dtype=torch.long)\n",
    "\n",
    "        y = self.labels[interval[0]][interval[1]: interval[2]]\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "        return Data(x=X.unsqueeze(0), edge_index=edge_index, y=y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 2489564/2489564 [00:36<00:00, 68253.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 2421935/2421935 [00:34<00:00, 69353.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1982955/1982955 [00:28<00:00, 70567.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1902145/1902145 [00:27<00:00, 69009.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1815382/1815382 [00:26<00:00, 68672.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1708059/1708059 [00:23<00:00, 72146.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1593459/1593459 [00:23<00:00, 68172.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1451386/1451386 [00:20<00:00, 72418.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1383947/1383947 [00:20<00:00, 66689.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1337974/1337974 [00:18<00:00, 72206.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1350866/1350866 [00:18<00:00, 71376.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1332753/1332753 [00:20<00:00, 64510.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1143643/1143643 [00:15<00:00, 72306.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1070437/1070437 [00:14<00:00, 72327.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1019911/1019911 [00:14<00:00, 72710.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 903383/903383 [00:12<00:00, 72007.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 832574/832574 [00:11<00:00, 72597.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 803732/803732 [00:13<00:00, 59234.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 586176/586176 [00:08<00:00, 72966.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 644441/644441 [00:08<00:00, 72753.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 467099/467099 [00:06<00:00, 72087.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 508184/508184 [00:06<00:00, 72750.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1560408/1560408 [00:21<00:00, 73199.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 572274/572274 [00:08<00:00, 70679.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 37858.87it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "width = 100\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "for chrm in chrom_names:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "            ints_in.append([chrm, interval[0], interval[1]])\n",
    "        else:\n",
    "            ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 2, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_chr1' '1_chr1' '1_chr1' ... '0_chr18' '0_chr8' '0_chr6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "np.random.seed(42)\n",
    "equalized = np.vstack((ints_in, ints_out))\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]\n",
    "\n",
    "labels = np.array([1]*len(ints_in) + [0]*len(ints_out))\n",
    "chromes = [inter[0] for inter in equalized]\n",
    "strat_labels = np.array([f\"{label}_{chrom}\" for label, chrom in zip(labels, chromes)])\n",
    "print(strat_labels)\n",
    "  \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_inds, test_inds = next(sss.split(equalized, strat_labels))\n",
    "  \n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                            DNA, DNA_features,\n",
    "                            ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                           DNA, DNA_features,\n",
    "                           ZDNA, test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "from torch_geometric.loader import DataLoader\n",
    "params = {'batch_size':32,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphZSAGEConv_11L(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphZSAGEConv_11L, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = SAGEConv(1950, 1024)\n",
    "        self.conv2 = SAGEConv(1024, 1024)\n",
    "        self.conv3 = SAGEConv(1024, 512)\n",
    "        self.conv4 = SAGEConv(512, 512)\n",
    "        self.conv5 = SAGEConv(512, 256)\n",
    "        \n",
    "        self.conv6 = SAGEConv(256, 256)\n",
    "        self.conv7 = SAGEConv(256, 128)\n",
    "        self.conv8 = SAGEConv(128, 128)\n",
    "        self.conv9 = SAGEConv(128, 64)\n",
    "        self.conv10 = SAGEConv(64, 64)\n",
    "        \n",
    "        self.conv11 = SAGEConv(64, 2)\n",
    "        \n",
    "        self.norm1 = torch.nn.GroupNorm(num_groups=512, num_channels=1024)\n",
    "        self.norm2 = torch.nn.GroupNorm(num_groups=512, num_channels=1024)\n",
    "        self.norm3 = torch.nn.GroupNorm(num_groups=256, num_channels=512)\n",
    "        self.norm4 = torch.nn.GroupNorm(num_groups=256, num_channels=512)\n",
    "        self.norm5 = torch.nn.GroupNorm(num_groups=128, num_channels=256)\n",
    "        self.norm6 = torch.nn.GroupNorm(num_groups=128, num_channels=256)\n",
    "        self.norm7 = torch.nn.GroupNorm(num_groups=64, num_channels=128)\n",
    "        self.norm8 = torch.nn.GroupNorm(num_groups=64, num_channels=128)\n",
    "        self.norm9 = torch.nn.GroupNorm(num_groups=32, num_channels=64)\n",
    "        self.norm10 = torch.nn.GroupNorm(num_groups=32, num_channels=64)\n",
    "\n",
    "    def forward(self, x, edge):\n",
    "        \n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        \n",
    "        x = self.conv1(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm1(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm2(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        \n",
    "        x = self.conv3(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm3(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv4(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm4(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv5(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm5(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv6(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm6(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv7(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm7(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv8(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm8(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv9(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm9(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv10(x, edge)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm10(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv11(x, edge)\n",
    "\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphZSAGEConv_11L(\n",
       "  (conv1): SAGEConv(1950, 1024, aggr=mean)\n",
       "  (conv2): SAGEConv(1024, 1024, aggr=mean)\n",
       "  (conv3): SAGEConv(1024, 512, aggr=mean)\n",
       "  (conv4): SAGEConv(512, 512, aggr=mean)\n",
       "  (conv5): SAGEConv(512, 256, aggr=mean)\n",
       "  (conv6): SAGEConv(256, 256, aggr=mean)\n",
       "  (conv7): SAGEConv(256, 128, aggr=mean)\n",
       "  (conv8): SAGEConv(128, 128, aggr=mean)\n",
       "  (conv9): SAGEConv(128, 64, aggr=mean)\n",
       "  (conv10): SAGEConv(64, 64, aggr=mean)\n",
       "  (conv11): SAGEConv(64, 2, aggr=mean)\n",
       "  (norm1): GroupNorm(512, 1024, eps=1e-05, affine=True)\n",
       "  (norm2): GroupNorm(512, 1024, eps=1e-05, affine=True)\n",
       "  (norm3): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
       "  (norm4): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
       "  (norm5): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
       "  (norm6): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
       "  (norm7): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
       "  (norm8): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
       "  (norm9): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "  (norm10): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphZSAGEConv_11L()\n",
    "model.load_state_dict(torch.load(\"GraphZSAGEConv_11L.pt\"))\n",
    "#model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum methods: IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in ./local/python3.9.0/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (2.3.0+cu121)\n",
      "Requirement already satisfied: tqdm in ./local/python3.9.0/lib/python3.9/site-packages (from captum) (4.66.4)\n",
      "Requirement already satisfied: filelock in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (1.13.0)\n",
      "Requirement already satisfied: networkx in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in ./local/python3.9.0/lib/python3.9/site-packages (from torch>=1.6->captum) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./local/python3.9.0/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->captum) (12.5.82)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./local/python3.9.0/lib/python3.9/site-packages (from matplotlib->captum) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./local/python3.9.0/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->captum) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in ./local/python3.9.0/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./local/python3.9.0/lib/python3.9/site-packages (from jinja2->torch>=1.6->captum) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./local/python3.9.0/lib/python3.9/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count = 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/27121 [00:00<?, ?it/s]/home/alapteva/local/python3.9.0/lib/python3.9/site-packages/torch_geometric/explain/explainer.py:193: UserWarning: The 'target' should not be provided for the explanation type 'model'\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 27121/27121 [9:36:40<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 9h 20min 52s, sys: 15min 38s, total: 9h 36min 31s\n",
      "Wall time: 9h 36min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_count =1950\n",
    "mean_1 = np.zeros(1950, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "        \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge, target=1)\n",
    "        node_mask = explanation.node_mask\n",
    "\n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950,)\n",
      "[-1.84972169e-01 -6.31486791e-02 -2.29900256e-02 ... -1.79317337e-15\n",
      " -5.23944621e-10  9.22915443e-07]\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.84972169e-01, -6.31486791e-02, -2.29900256e-02, ...,\n",
       "       -1.79317337e-15, -5.23944621e-10,  9.22915443e-07])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_11L_IG.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# salency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.base_model(x, edge_index) \n",
    "        a = out[:, :, 1] \n",
    "        return a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrappedmodel = WrappedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=CaptumExplainer('Saliency'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 27121/27121 [36:28<00:00, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 31min 43s, sys: 4min 19s, total: 36min 2s\n",
      "Wall time: 36min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_count =1950\n",
    "mean_1 = np.zeros(1950, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "        \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge, target=1)\n",
    "        node_mask = explanation.node_mask\n",
    "\n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76419802e-02, 1.97136785e-02, 2.26526768e-02, ...,\n",
       "       2.68914499e-09, 5.58110266e-05, 1.61702059e-03])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_11L_Saliency.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7642e-02, 1.9714e-02, 2.2653e-02,  ..., 2.6891e-09, 5.5811e-05,\n",
       "        1.6170e-03], dtype=torch.float64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('GraphZSAGEConv_11L_Saliency.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IxG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=CaptumExplainer('InputXGradient'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 27121/27121 [36:48<00:00, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 32min 10s, sys: 4min 13s, total: 36min 23s\n",
      "Wall time: 36min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_count =1950\n",
    "mean_1 = np.zeros(1950, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "   \n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "     \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "      \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "      \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge)\n",
    "        node_mask = explanation.node_mask\n",
    "        \n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.detach().cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950,)\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.42047548e-04,  4.99803764e-03,  4.66836353e-03, ...,\n",
       "        1.59512461e-18, -7.59804732e-11, -4.61208974e-08])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_11L_IxG.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=wrappedmodel,\n",
    "    algorithm=GNNExplainer(epochs=50),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                          | 527/27121 [13:58<12:33:23,  1.70s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_count =1950\n",
    "mean_1 = np.zeros(1950, dtype=float)\n",
    "cnt= 0\n",
    "cc = 0\n",
    "\n",
    "device = torch.device(f'cuda:{1}')\n",
    "with torch.cuda.device(device):\n",
    "    model = model.to('cuda:1')\n",
    "   \n",
    "    for dt in tqdm(loader_test):\n",
    "        \n",
    "        x, edge, y = dt.x.to('cuda:1'), dt.edge_index.to('cuda:1'), dt.y.to('cuda:1').long()\n",
    "     \n",
    "        output = model(x, edge)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "      \n",
    "        idxs = []\n",
    "        for i in range(width):\n",
    "            if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "                idxs.append(i)\n",
    "      \n",
    "        torch.cuda.empty_cache()\n",
    "        explanation = explainer(x.squeeze(), edge)\n",
    "        node_mask = explanation.node_mask\n",
    "        \n",
    "        if node_mask[idxs, :].shape != (0, features_count):\n",
    "            node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "            node_mask = np.array(node_mask.detach().cpu())\n",
    "            mean_1 += node_mask\n",
    "            cnt += 1\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'GraphZSAGEConv_11L_GNN_explainer.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyhton 3.9.0 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
